{"cells":[{"cell_type":"code","source":["from pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.feature import HashingTF, Tokenizer\nraw_data = spark.read.csv('FileStore/tables/SMSSpamCollection',sep='\\t')\nraw_data.show()"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["from pyspark.sql.functions import *\nraw_data = raw_data.select(col(\"_c0\").alias(\"label\"), col(\"_c1\").alias(\"text\"))\nraw_data.show()"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["from pyspark.ml.feature import Tokenizer\ntokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\nwordsDataFrame = tokenizer.transform(raw_data)\nwordsDataFrame.show()"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["from pyspark.ml.feature import StopWordsRemover\nremover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\nfiltered_words = remover.transform(wordsDataFrame)\nfiltered_words.show()"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["from pyspark.ml.feature import StringIndexer\nindexer = StringIndexer(inputCol=\"label\", outputCol=\"labelIndex\")\nindexed_df = indexer.fit(filtered_words).transform(filtered_words)\nindexed_df.show()"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["from pyspark.ml.feature import HashingTF, IDF\nhashingTF = HashingTF(inputCol=\"filtered_words\", outputCol=\"rawFeatures\", numFeatures=10000)\nfeaturizedData = hashingTF.transform(indexed_df)\nfeaturizedData.show()\nidf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\nidfModel = idf.fit(featurizedData)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["rescaledData = idfModel.transform(featurizedData)\ntrain, test = rescaledData.randomSplit([0.8, 0.2],seed =11L)\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.ml.classification import LogisticRegression\nlr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8,labelCol=\"labelIndex\", featuresCol=\"features\")\nlrModel = lr.fit(train)\npredictions = lrModel.transform(test)\npredictions.select(\"prediction\", \"labelIndex\", \"features\").show(5)\n"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["predictions.select(\"prediction\", \"labelIndex\", \"features\").show(5)\n"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["from pyspark.ml.evaluation import MulticlassClassificationEvaluator\nevaluator = MulticlassClassificationEvaluator(\n    labelCol=\"labelIndex\", predictionCol=\"prediction\", metricName=\"accuracy\")\naccuracy = evaluator.evaluate(predictions)\nprint(accuracy)\nprint(\"Test Error = %g \" % (1.0 - accuracy))"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["### LogisticRegression"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import Tokenizer\nfrom pyspark.ml.feature import StopWordsRemover\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.feature import HashingTF, IDF\n\n(trainingData, testData) = raw_data.randomSplit([0.8, 0.2],seed = 11L)\n\ntokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\nremover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\nindexer = StringIndexer(inputCol=\"label\", outputCol=\"labelIndex\")\n\nhashingTF = HashingTF(inputCol=\"filtered_words\", outputCol=\"rawFeatures\", numFeatures=10000)\nidf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\nfrom pyspark.ml.classification import LogisticRegression\nlr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8,labelCol=\"labelIndex\", featuresCol=\"features\")\n\nfrom pyspark.ml import Pipeline\npipeline_lg = Pipeline(stages=[tokenizer, remover,indexer, hashingTF, idf, lr])\npipeline_lg_model = pipeline_lg.fit(trainingData)\n\npredictions_lg = pipeline_lg_model.transform(testData)\n\nevaluator = MulticlassClassificationEvaluator(\n    labelCol=\"labelIndex\", predictionCol=\"prediction\", metricName=\"accuracy\")\naccuracy_lg = evaluator.evaluate(predictions_lg)\nprint(\"Accuracy_lg  = %g \"%(accuracy_lg))\nprint(\"Test Error = %g \" % (1.0 - accuracy_lg))"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["## DecisionTreeClassifier"],"metadata":{}},{"cell_type":"code","source":["\nfrom pyspark.ml.classification import DecisionTreeClassifier\ndt = DecisionTreeClassifier(labelCol=\"labelIndex\", featuresCol=\"features\")\n\npipeline_dt = Pipeline(stages=[tokenizer, remover,indexer, hashingTF, idf, dt])\npipeline_dt_model = pipeline_dt.fit(trainingData)\npredictions_dt = pipeline_dt_model.transform(testData)\n\naccuracy_dt = evaluator.evaluate(predictions_dt )\nprint(\"Dccuracy_dt  = %g \"%(accuracy_dt))\nprint(\"Test Error = %g \" % (1.0 - accuracy_dt))"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["## RandomForestClassifier"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.classification import RandomForestClassifier\nrf = RandomForestClassifier(labelCol=\"labelIndex\", featuresCol=\"features\")\npipeline_rf = Pipeline(stages=[tokenizer, remover,indexer, hashingTF, idf, rf])\npipeline_rf_model = pipeline_rf.fit(trainingData)\npredictions_rf = pipeline_rf_model.transform(testData)\n\nevaluator_rf = MulticlassClassificationEvaluator(\n    labelCol=\"labelIndex\", predictionCol=\"prediction\", metricName=\"accuracy\")\npredictions_rf = evaluator_rf.evaluate(predictions_rf)\n\nprint(\"Accuracy_rf  = %g \"%(predictions_rf))\nprint(\"Test Error = %g \" % (1.0 - predictions_rf))"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["### Gradient-boosted tree classifier"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.classification import GBTClassifier\ngbt = GBTClassifier(labelCol=\"labelIndex\", featuresCol=\"features\",maxIter=10)\npipeline_gbt = Pipeline(stages=[tokenizer, remover,indexer, hashingTF, idf, gbt])\npipeline_gbt_model = pipeline_gbt.fit(trainingData)\npredictions_gbt = pipeline_gbt_model.transform(testData)\n\nevaluator_gbt = MulticlassClassificationEvaluator(\n    labelCol=\"labelIndex\", predictionCol=\"prediction\", metricName=\"accuracy\")\n\naccuracy_gbt = evaluator_gbt.evaluate(predictions_gbt)\nprint(\"Accuracy_rf  = %g \"%(accuracy_gbt))\nprint(\"Test Error = %g \" % (1.0 - accuracy_gbt))"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":18}],"metadata":{"name":"Classification","notebookId":3064992207721520},"nbformat":4,"nbformat_minor":0}
